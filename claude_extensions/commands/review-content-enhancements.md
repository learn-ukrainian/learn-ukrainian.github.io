# Review-Content Enhancements: AI Detection & Humanity Checks

> **Purpose:** Catch AI-generated "slop" that passes structural checks but lacks human voice, cultural authenticity, or pedagogical warmth.

---

## Section 13: LLM Fingerprint Detection (NEW)

**Goal:** Flag content that exhibits telltale signs of lazy AI generation.

### 13a. Overused AI Phrases (Auto-flag)

**Common LLM Clich√©s to Flag:**

English:
- ‚ùå "It's important to note that..."
- ‚ùå "It's worth noting that..."
- ‚ùå "As we've seen..."
- ‚ùå "Let's dive into..."
- ‚ùå "In today's lesson..." (when module isn't time-bound)
- ‚ùå "Mastering [X] is crucial for..."
- ‚ùå "This will help you unlock..."
- ‚ùå "Think of it as..." (overused analogy starter)
- ‚ùå "In conclusion..." (textbook ending)
- ‚ùå "To summarize..." (unless checkpoint/integration)
- ‚ùå "Additionally, ..." "Furthermore, ..." "Moreover, ..." (stacked transitions without necessity)
- ‚ùå "Now that we've covered..."

Ukrainian:
- ‚ùå "–í–∞–∂–ª–∏–≤–æ –∑–∞–∑–Ω–∞—á–∏—Ç–∏, —â–æ..."
- ‚ùå "–Ø–∫ –º–∏ –≤–∂–µ –±–∞—á–∏–ª–∏..."
- ‚ùå "–î–∞–≤–∞–π—Ç–µ –∑–∞–≥–ª–∏–±–∏–º–æ—Å—å —É..."
- ‚ùå "–£ —Å—å–æ–≥–æ–¥–Ω—ñ—à–Ω—å–æ–º—É —É—Ä–æ—Ü—ñ..."
- ‚ùå "–û–≤–æ–ª–æ–¥—ñ–Ω–Ω—è [X] —î –≤–∞–∂–ª–∏–≤–∏–º –¥–ª—è..."

**Check:** If 3+ of these phrases appear in one module, flag as **LLM_CLICHE_OVERUSE**.

**Fix:** Rewrite with natural Ukrainian/English teaching voice.

---

### 13b. False Specificity (The "Generic Disguise" Test)

**Pattern:** AI claims specificity but stays vague.

‚ùå **Fake Specific (AI-generated):**
```markdown
–£—è–≤—ñ—Ç—å —Å–æ–±—ñ —Å–∏—Ç—É–∞—Ü—ñ—é: –≤–∏ –π–¥–µ—Ç–µ –¥–æ –º–∞–≥–∞–∑–∏–Ω—É —ñ –∫—É–ø—É—î—Ç–µ —ó–∂—É.
```
- **Issue:** "–º–∞–≥–∞–∑–∏–Ω" (generic store), "—ó–∂–∞" (generic food) - no actual detail.

‚úÖ **Real Specific (Human):**
```markdown
–£—è–≤—ñ—Ç—å: –≤–∏ –Ω–∞ –ë–µ—Å–∞—Ä–∞–±—Å—å–∫–æ–º—É —Ä–∏–Ω–∫—É –≤ –ö–∏—î–≤—ñ. –ü—Ä–æ–¥–∞–≤–µ—Ü—å –ø—Ä–æ–ø–æ–Ω—É—î –≤–∞–º —Å–≤—ñ–∂—É –ø–∞–ª—è–Ω–∏—Ü—é ‚Äî —â–µ —Ç–µ–ø–ª—É! –í–∏ –∫–∞–∂–µ—Ç–µ: ¬´–í—ñ–∑—å–º—É –¥–≤—ñ¬ª.
```
- **Why it works:** Named place (–ë–µ—Å–∞—Ä–∞–±—Å—å–∫–∏–π —Ä–∏–Ω–æ–∫, –ö–∏—ó–≤), specific item (–ø–∞–ª—è–Ω–∏—Ü—è), sensory detail (—â–µ —Ç–µ–ø–ª—É), dialogue.

**Check:**
- Count named places, people, foods, cultural references
- If module has <3 specific Ukrainian references (place names, traditional foods, cultural practices), flag as **FALSE_SPECIFICITY**

---

### 13c. Certainty Overload (The "AI Overconfidence" Test)

**Pattern:** AI uses absolute statements where humans would hedge.

‚ùå **Robotic (AI certainty):**
```markdown
–î—ñ—î—Å–ª–æ–≤–∞ —Ä—É—Ö—É –∑–∞–≤–∂–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –∑ –ø—Ä–µ—Ñ—ñ–∫—Å–∞–º–∏.
–¶–µ–π –≤–∏—Ä–∞–∑ –Ω—ñ–∫–æ–ª–∏ –Ω–µ –≤–∂–∏–≤–∞—î—Ç—å—Å—è –≤ —Ä–æ–∑–º–æ–≤–Ω—ñ–π –º–æ–≤—ñ.
```

‚úÖ **Human (natural qualification):**
```markdown
–î—ñ—î—Å–ª–æ–≤–∞ —Ä—É—Ö—É —á–∞—Å—Ç–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –∑ –ø—Ä–µ—Ñ—ñ–∫—Å–∞–º–∏.
–¶–µ–π –≤–∏—Ä–∞–∑ —Ä—ñ–¥–∫–æ –∑—É—Å—Ç—Ä—ñ—á–∞—î—Ç—å—Å—è –≤ —Ä–æ–∑–º–æ–≤–Ω—ñ–π –º–æ–≤—ñ ‚Äî —É–∫—Ä–∞—ó–Ω—Ü—ñ –≤—ñ–¥–¥–∞—é—Ç—å –ø–µ—Ä–µ–≤–∞–≥—É –ø—Ä–æ—Å—Ç—ñ—à–∏–º —Ñ–æ—Ä–º–∞–º.
```

**Check:** Count absolutes (–∑–∞–≤–∂–¥–∏, –Ω—ñ–∫–æ–ª–∏, –≤—Å—ñ, –∂–æ–¥–µ–Ω, –∫–æ–∂–µ–Ω, must, never, always, every).
- If >5 unqualified absolutes in a section, flag as **OVERCONFIDENCE**

**Fix:** Add hedging (—á–∞—Å—Ç–æ, –∑–∞–∑–≤–∏—á–∞–π, generally, typically, often) and reasoning (—á–æ–º—É? –±–æ...).

---

### 13d. Anecdotal Absence (The "Teacher Story" Test)

**Goal:** Real teachers tell stories. AI lists facts.

**Check:**
- Does the module include at least ONE:
  - Personal anecdote ("–ö–æ–ª–∏ —è –≤–ø–µ—Ä—à–µ...") [if teacher voice]
  - Student scenario with stakes ("–£—è–≤—ñ—Ç—å: –≤–∏ –Ω–∞ —Å–ø—ñ–≤–±–µ—Å—ñ–¥—ñ —ñ –∑–∞–±—É–ª–∏, —è–∫ —Å–∫–∞–∑–∞—Ç–∏...")
  - Cultural story ("–í –£–∫—Ä–∞—ó–Ω—ñ –∫–∞–∂—É—Ç—å, —â–æ...")
  - Historical context with narrative ("–£ 1991 —Ä–æ—Ü—ñ, –∫–æ–ª–∏...")

**Pass:** Module has ‚â•1 narrative moment (story arc: setup ‚Üí conflict/question ‚Üí resolution).
**Fail:** Module is 100% expository (just facts, no storytelling).

**Flag as:** **NO_NARRATIVE_VOICE** (B1+ only; A1/A2 exempt due to language limitations).

---

### 13e. Predictability Test (The "Surprise Factor")

**Pattern:** AI is formulaic. Human teaching has unexpected turns.

**Check:** Does the module have ANY of these?
- [ ] Surprising fact that challenges assumptions ("–ê–ª–µ —Ç—É—Ç —î —Å—é—Ä–ø—Ä–∏–∑!")
- [ ] Counterintuitive example ("–ó–¥–∞—î—Ç—å—Å—è –¥–∏–≤–Ω–æ, –∞–ª–µ...")
- [ ] Playful contradiction ("–í–∏ –¥—É–º–∞—î—Ç–µ, —â–æ X? –ù–∞—Å–ø—Ä–∞–≤–¥—ñ...")
- [ ] Unexpected cultural insight ("–£–∫—Ä–∞—ó–Ω—Ü—ñ —Ä–æ–±–ª—è—Ç—å —ñ–Ω–∞–∫—à–µ, –Ω—ñ–∂ –≤–∏ –æ—á—ñ–∫—É—î—Ç–µ...")
- [ ] Grammar "trick" reveal ("–û—Å—å —Å–µ–∫—Ä–µ—Ç, —è–∫–∏–π —Å–ø—Ä–æ—â—É—î –≤—Å–µ...")

**Fail:** Module follows 100% predictable path (definition ‚Üí table ‚Üí example ‚Üí practice). Zero surprises.
**Pass:** Module has ‚â•1 moment where learner thinks "Oh! I didn't expect that!"

**Flag as:** **PREDICTABLE_PEDAGOGY**

---

### 13f. Emotional Flatness (The "Boredom Detector")

**Pattern:** AI rarely expresses emotion. Humans do.

**Check for Emotional Markers:**
- Exclamations: ! (excitement, surprise)
- Rhetorical questions: ? (engagement, challenge)
- Emphatic words: –¥—É–∂–µ, really, especially, particularly
- Evaluative language: beautiful, clever, tricky, surprising
- Direct address: —Ç–∏/–≤–∏ (you), –¥–∞–≤–∞–π—Ç–µ (let's)

**Density Check:**
- Count emotional markers per 100 words
- **Fail:** <1 per 100 words (flat, robotic)
- **Pass:** 2-4 per 100 words (conversational)
- **Overboard:** >6 per 100 words (too gimmicky)

**Flag as:** **EMOTIONAL_FLATNESS** (if fail threshold).

---

### 13g. Teacher Voice Consistency (NEW)

**Goal:** Ensure a consistent pedagogical persona throughout.

**Check:**
- Does the voice shift between formal/informal without reason?
- Does the teacher persona stay consistent (encouraging vs. strict vs. playful)?
- Are pronouns consistent (–≤–∏/formal vs. —Ç–∏/informal)?

‚ùå **Inconsistent:**
```markdown
Paragraph 1: "–î–∞–≤–∞–π—Ç–µ —Ä–æ–∑–≥–ª—è–Ω–µ–º–æ..." (we together - inclusive)
Paragraph 3: "–í–∞–º –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–∞–ø–∞–º'—è—Ç–∞—Ç–∏..." (you - distant)
```

‚úÖ **Consistent:**
```markdown
All paragraphs: "–ú–∏ —Ä–æ–∑–≥–ª—è–Ω–µ–º–æ..." "–ú–∏ –∑–∞–ø–∞–º'—è—Ç–∞—î–º–æ..." (consistent "we" voice)
```

**Check:** Flag if pronouns/tone shift >2 times without pedagogical reason.

**Flag as:** **INCONSISTENT_VOICE**

---

### 13h. Depth of Explanation (The "Why Depth" Test)

**Pattern:** AI stops at surface. Humans dig into "why."

**Example:**

‚ùå **Shallow (AI):**
```markdown
Perfective aspect shows completed action. Use it for results.
```

‚úÖ **Deep (Human):**
```markdown
Why do Ukrainians care so much about aspect?

Because the verb form tells you whether to mentally "close the file" or not.

"–Ø –ø–∏—Å–∞–≤ –ª–∏—Å—Ç" ‚Üí File still open. Maybe I'm still writing, maybe I stopped but didn't finish.
"–Ø –Ω–∞–ø–∏—Å–∞–≤ –ª–∏—Å—Ç" ‚Üí File closed. The letter exists now. Result achieved.

English doesn't force this choice. Ukrainian does. Every. Single. Time.
```

**Check:** For each grammar concept, verify:
- [ ] **What:** Definition provided
- [ ] **How:** Usage examples provided
- [ ] **Why it matters:** Cultural/linguistic reason explained
- [ ] **Common mistake:** What learners get wrong and why

**Fail:** Module teaches "what" and "how" but never "why."

**Flag as:** **MISSING_WHY_LAYER**

---

### 13i. Cultural Resonance (The "Soul" Test)

**Goal:** Ensure Ukrainian culture is woven in, not sprinkled on.

**Superficial Integration (AI):**
```markdown
üé¨ Pop Culture Moment: Ukrainians like borshch!
```
- **Issue:** Random fact without connection to grammar/vocab.

**Deep Integration (Human):**
```markdown
–£–∫—Ä–∞—ó–Ω—Ü—ñ –∫–∞–∂—É—Ç—å: "–ù–µ —Ç–æ–π –±–æ—Ä—â, —â–æ –≤ –≥–æ—Ä—â–∏–∫, –∞ —Ç–æ–π, —â–æ –≤ —Ä–æ—Ç—ñ" (It's not the soup in the pot that counts, but the one in your mouth).

–ó–≤–µ—Ä–Ω—ñ—Ç—å —É–≤–∞–≥—É: **–≤ –≥–æ—Ä—â–∏–∫** (Accusative), **–≤ —Ä–æ—Ç—ñ** (Locative).

–ß–æ–º—É —Ä—ñ–∑–Ω—ñ –≤—ñ–¥–º—ñ–Ω–∫–∏? –ë–æ –æ–¥–∏–Ω ‚Äî –∫—É–¥–∏ –∫–ª–∞–¥—É—Ç—å (–Ω–∞–ø—Ä—è–º–æ–∫), —ñ–Ω—à–∏–π ‚Äî –¥–µ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è (–º—ñ—Å—Ü–µ).

–¶—è —Ä—ñ–∑–Ω–∏—Ü—è ‚Äî —Å—É—Ç—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –≥—Ä–∞–º–∞—Ç–∏–∫–∏.
```

**Check:**
- [ ] Cultural content connects to grammar lesson (not random)
- [ ] Proverbs/idioms demonstrate grammatical structure
- [ ] Examples use Ukrainian reality (not translated Western scenarios)

**Fail:** Culture is decorative (random facts in boxes). Grammar is separate.
**Pass:** Culture IS the vehicle for teaching grammar.

**Flag as:** **DECORATIVE_CULTURE** (if fail).

---

## Section 14: Human Warmth Checklist (NEW)

**These elements make learners feel a human teacher is present:**

### 14a. Direct Address
- [ ] Uses "you" (—Ç–∏/–≤–∏) to speak directly to learner
- [ ] Uses "we" (–º–∏) to create partnership ("Let's explore...")
- [ ] Acknowledges learner struggles ("This is tricky, I know")

### 14b. Encouragement
- [ ] At least 1 encouraging phrase per module:
  - "You've got this!"
  - "–ù–µ —Ö–≤–∏–ª—é–π—Ç–µ—Å—è, —Ü–µ –∑—Ä–æ–∑—É–º—ñ—î –∫–æ–∂–µ–Ω"
  - "With practice, this becomes natural"

### 14c. Anticipates Confusion
- [ ] Addresses common mistakes BEFORE learner makes them
- [ ] "You might think X, but actually..."
- [ ] "Students often confuse X and Y. Here's how to remember..."

### 14d. Real-World Validation
- [ ] Shows learner why THIS lesson matters NOW
- [ ] "After this module, you'll be able to..."
- [ ] "This unlocks [real-world skill]"

**Fail:** Module has <2 of these warmth markers.
**Pass:** Module has ‚â•3 warmth markers.

**Flag as:** **COLD_PEDAGOGY**

---

## Section 15: Richness Red Flags (AUTO-FAIL)

**These are fatal flaws that indicate AI slop:**

### 15a. The "ChatGPT Default Voice"

**Pattern Recognition:**
```markdown
Welcome to Module X! In this lesson, we'll explore...
First, let's understand... Then, we'll dive deeper into...
By the end of this module, you'll be able to...
```

**Why it's bad:** This is GPT's default scaffolding template. Zero personality.

**Auto-fail if:** Module opens with this exact structure.

### 15b. The "Bullet Point Barrage"

**Pattern:**
```markdown
Here are 5 key points:
- Point 1
- Point 2
- Point 3
- Point 4
- Point 5

Now let's look at 3 examples:
- Example 1
- Example 2
- Example 3
```

**Why it's bad:** No narrative flow. Just a list generator.

**Auto-fail if:** >50% of module is bullet lists without prose paragraphs.

### 15c. The "Wikipedia Copy-Paste" Syndrome

**Pattern:**
```markdown
The Dative case (Ukrainian: –¥–∞–≤–∞–ª—å–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫) is a grammatical case
used in the Ukrainian language to indicate the indirect object of a verb.
```

**Why it's bad:** Encyclopedic tone. No teaching warmth. Passive voice overload.

**Auto-fail if:** Module uses encyclopedic definitions without rewriting for learner voice.

### 15d. The "Engagement Box Faker"

**Pattern:**
```markdown
üí° Did You Know?
Ukrainian has 7 cases!

üí° Pro Tip:
Remember to use the Dative case with these verbs.

üí° Cultural Note:
Ukrainians value hospitality.
```

**Why it's bad:** Boxes contain obvious/useless info. Padding, not value.

**Auto-fail if:** >50% of engagement boxes just restate what body text already said.

---

## Section 16: Fix Strategies for AI-Generated Content

**When you detect AI slop, apply these fixes:**

### Strategy 1: Add Sensory Detail
‚ùå **Generic:** "–õ—é–¥–∏–Ω–∞ –≥–æ—Ç—É—î —ó–∂—É"
‚úÖ **Vivid:** "–ó–∞–ø–∞—Ö –±–æ—Ä—â—É –Ω–∞–ø–æ–≤–Ω—é—î –∫—É—Ö–Ω—é ‚Äî –±—É—Ä—è—á–∫–∏, —á–∞—Å–Ω–∏–∫, –∫—Ä—ñ–ø"

### Strategy 2: Name Everything
‚ùå **Vague:** "–Ø –∫—É–ø–∏–≤ —Ö–ª—ñ–± —É –º–∞–≥–∞–∑–∏–Ω—ñ"
‚úÖ **Specific:** "–Ø –∫—É–ø–∏–≤ –ø–∞–ª—è–Ω–∏—Ü—é –≤ –±—É–ª–æ—á–Ω—ñ–π '–•–ª—ñ–±–Ω–∏–π –¥—ñ–º' –Ω–∞ –≤—É–ª–∏—Ü—ñ –•—Ä–µ—â–∞—Ç–∏–∫"

### Strategy 3: Add "Why" Layer
‚ùå **Shallow:** "Use perfective for results"
‚úÖ **Deep:** "–ß–æ–º—É –≤–∞–∂–ª–∏–≤–æ? –ë–æ —É–∫—Ä–∞—ó–Ω–µ—Ü—å –ø–æ—á—É—î '—è —Ä–æ–±–∏–≤' —ñ –∑–∞–ø–∏—Ç–∞—î: '–Ü —â–æ? –ó—Ä–æ–±–∏–≤ —á–∏ –Ω—ñ?' –ù–µ–¥–æ–∫–æ–Ω–∞–Ω–∏–π –≤–∏–¥ –∑–∞–ª–∏—à–∞—î –ø–∏—Ç–∞–Ω–Ω—è –≤—ñ–¥–∫—Ä–∏—Ç–∏–º."

### Strategy 4: Replace Certainty with Reality
‚ùå **Absolute:** "–¶–µ –∑–∞–≤–∂–¥–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ"
‚úÖ **Nuanced:** "–ë—ñ–ª—å—à—ñ—Å—Ç—å —É–∫—Ä–∞—ó–Ω—Ü—ñ–≤ —Å–∫–∞–∂–µ —ñ–Ω–∞–∫—à–µ. –•–æ—á —Ç–µ—Ö–Ω—ñ—á–Ω–æ –æ–±–∏–¥–≤–∞ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ —ñ—Å–Ω—É—é—Ç—å, –æ–¥–∏–Ω –∑–≤—É—á–∏—Ç—å –ø—Ä–∏—Ä–æ–¥–Ω—ñ—à–µ."

### Strategy 5: Inject Story
‚ùå **Factual:** "Genitive shows possession"
‚úÖ **Narrative:** "–ú–∞—Ä—ñ—è –π–¥–µ –¥–æ –º–∞–º–∏. –ß–æ–º—É '–º–∞–º–∏', –∞ –Ω–µ '–º–∞–º–∞'? –ë–æ —Ü–µ ‚Äî –º–∞–º–∏–Ω –¥—ñ–º, –º–∞–º–∏–Ω–∞ –≤—É–ª–∏—Ü—è, –º–∞–º–∏–Ω–µ –º—ñ—Å—Ç–æ. –†–æ–¥–æ–≤–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫ —Å—Ç–≤–æ—Ä—é—î –∑–≤'—è–∑–æ–∫: –Ω–µ –ø—Ä–æ—Å—Ç–æ '–π—Ç–∏ –¥–æ', –∞ '–π—Ç–∏ –¥–æ –∫–æ–≥–æ—Å—å —Å–≤–æ–≥–æ'."

---

## Implementation Checklist

**For each module review, add these steps:**

**Step 13: Run LLM Fingerprint Detection**
- [ ] Check for overused AI phrases (13a)
- [ ] Verify real specificity vs. fake (13b)
- [ ] Count certainty markers (13c)
- [ ] Look for narrative moments (13d)
- [ ] Check for surprises (13e)
- [ ] Measure emotional density (13f)
- [ ] Verify voice consistency (13g)
- [ ] Check "why" depth (13h)
- [ ] Assess cultural integration (13i)

**Step 14: Human Warmth Audit**
- [ ] Direct address present? (14a)
- [ ] Encouragement included? (14b)
- [ ] Confusion anticipated? (14c)
- [ ] Real-world validation? (14d)

**Step 15: Richness Red Flags**
- [ ] No ChatGPT default voice? (15a)
- [ ] No bullet barrage? (15b)
- [ ] No Wikipedia tone? (15c)
- [ ] Engagement boxes add value? (15d)

**Scoring:**
- **5/5:** All checks pass. Content feels authentically human.
- **4/5:** 1-2 minor flags. Mostly human, slight AI traces.
- **3/5:** 3-4 flags. Noticeably AI-generated but salvageable.
- **2/5:** 5+ flags. Heavy AI fingerprint. Needs rewrite.
- **1/5:** Auto-fail red flags present. Pure AI slop. Complete rewrite.

---

## Comparison: Before vs After Enhancements

### Example: Module Score Changes

**Module B1-08 (Aspect - Past Result/Process)**

**Before Enhancement (Old Review):**
- Coherence: 4/5
- Relevance: 5/5
- Educational: 4/5
- Language: 5/5
- Pedagogy: 4/5
- Immersion: 5/5
- Activities: 5/5
- Richness: 3/5
- **Overall: 4.4/5** ‚Üí ‚úÖ PASS

**Issues Noted:** "Minor repetition in examples"

**After Enhancement (New Review with AI Detection):**
- All previous scores: same
- **LLM Fingerprints Detected:**
  - ‚ùå Overused phrases: "–Ø–∫ –º–∏ –≤–∂–µ –±–∞—á–∏–ª–∏..." (appears 3x)
  - ‚ùå False specificity: Generic "–ª—é–¥–∏–Ω–∞ –π–¥–µ –¥–æ –º–∞–≥–∞–∑–∏–Ω—É" (no named places)
  - ‚ùå Predictable pedagogy: No surprise moments
  - ‚ùå Emotional flatness: 0.8 markers per 100 words (below threshold)
  - ‚ö†Ô∏è Missing "why" layer: Surface explanation only
- **Human Warmth:** 1/4 (missing encouragement, confusion anticipation)
- **Richness Red Flag:** Engagement boxes restate body text

**New Score: 3/5** ‚Üí ‚ö†Ô∏è NEEDS ENRICHMENT

**Why this matters:** Old review missed that content WORKS but lacks SOUL. New review catches this.

---

## Summary

**What These Enhancements Detect:**

1. **LLM Clich√©s** ‚Üí "It's important to note that..." spam
2. **Fake Specificity** ‚Üí Claims "specific" but stays generic
3. **AI Overconfidence** ‚Üí "Always" / "Never" without hedging
4. **Missing Stories** ‚Üí All facts, no narrative
5. **Predictability** ‚Üí Zero surprises or unexpected turns
6. **Emotional Flatness** ‚Üí No exclamations, questions, or warmth
7. **Voice Inconsistency** ‚Üí Persona shifts randomly
8. **Shallow Explanation** ‚Üí "What" and "How" but no "Why"
9. **Decorative Culture** ‚Üí Random Ukrainian facts, not integrated
10. **Cold Pedagogy** ‚Üí No teacher warmth, encouragement, or empathy

**Bottom Line:**
Your modules now pass structural/grammatical audits. These enhancements ensure they also pass the **HUMAN TEST** ‚Äî content that feels like a skilled teacher wrote it, not an algorithm.
